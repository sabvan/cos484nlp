# Replicating 'Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?'

This repository holds replica code from the paper [Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?](https://arxiv.org/abs/2407.16607). This was the final project for COS 484: Natural Language Processing completed with Caitlin Wang and Christina Zhang. Similar results were replicated using oscar-mini and Red-Pajama subset. Furthermore, the BPE Tokenizer attack was applied to new tokenizers, specifically, DeepSeek and 3 models of Qwen. Below is a summary of the code from the original authors:

"Given a BPE tokenizer, our attack infers its training data distribution with high precision, recovering e.g., the proportion of different natural languages, code, and sources of data. In general, the attack will work for any set of data categories that are reasonably expected to cover the training data and have different "word" distributions. In controlled experiments, our attack performs 2 to 5 *orders of magnitude* better than baselines based on tokenizer encoding efficiency or analysis of the vocabulary. In robustness experiments (see ยง6), we show that the attack remains strong even when the attacker does not have access to the same data distribution, or when not all data categories are known to the attacker."
